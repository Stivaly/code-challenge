# Proyecto ETL con BigQuery

Este proyecto consiste en un proceso ETL que extrae datos de un archivo CSV, los transforma y los carga en BigQuery. Fue desarrollado usando Python y las herramientas proporcionadas por Google Cloud Platform.

## Requisitos

- Python 3.11.3
- Google Cloud SDK
- [Otras dependencias se encuentran en `requirements.txt`]

# Referencia de los datos CSV

Online Retail. (2015). UCI Machine Learning Repository. https://doi.org/10.24432/C5BW33.

## Configuraci贸n del Ambiente

1. **Credenciales de GCP**: Coloque el archivo de credenciales `.json` proporcionado por GCP en el directorio `keys/`.
2. **Instalaci贸n de Google Cloud SDK**: Si a煤n no tiene instalado Google Cloud SDK en su m谩quina, siga las instrucciones en Google Cloud SDK Documentation para instalarlo.
3. **Autenticaci贸n**:
Una vez que tenga Google Cloud SDK instalado, ejecute el siguiente comando para autenticarse con su cuenta de Google:
    gcloud auth login

Luego, configure el proyecto de GCP con el siguiente c贸digo:
    gcloud config set project [etl-code-challenge]

4. **Configuraci贸n de las Credenciales**:

Establezca la variable de entorno GOOGLE_APPLICATION_CREDENTIALS en su m谩quina apuntando a la ubicaci贸n del archivo de credenciales.

En Windows (Powershell):
    $env:GOOGLE_APPLICATION_CREDENTIALS="C:\ruta\completa\al\archivo\de\credenciales.json"

En Linux o Mac:
    export GOOGLE_APPLICATION_CREDENTIALS="/ruta/completa/al/archivo/de/credenciales.json"

 Nota: Es importante establecer esta variable de entorno. Si est谩s trabajando con un entorno de desarrollo espec铆fico es posible que solo necesites hacerlo una vez por sesi贸n.

5. **Instalar Dependencias**: Ejecute el siguiente comando para instalar todas las dependencias necesarias: 
    pip install -r requirements.txt

## C贸mo ejecutar la consulta SQL

Ingresa al siguiente link para ejecutar las consultas de agregaci贸n y segmentaci贸n del proyecto directamente en BigQuery, luego de ejecutar el proceso ETL: 
    https://console.cloud.google.com/bigquery?sq=877558642730:c95480eb2fbd431d83e9d343fc874147


# Automatizaci贸n con Task Scheduler en Windows

Para automatizar, debido a que enfrent茅 muchos inconvenientes configurando tanto airflow como nncron, utilizo el Programador de tareas (Task Scheduler) en Windows. 

## Pasos para programar la automatizaci贸n:

1. Abre el Programador de tareas de Windows. Puedes encontrarlo en el men煤 "Herramientas administrativas" o buscarlo en el men煤 Inicio.

2. En el panel izquierdo, selecciona "Biblioteca del Programador de tareas" para crear una nueva tarea.

3. En la ventana derecha, haz clic en "Crear tarea b谩sica" para comenzar la configuraci贸n.

4. Dale un nombre a la tarea y proporciona una descripci贸n opcional. Luego, haz clic en "Siguiente".

5. Selecciona la opci贸n "Diariamente" o elige una frecuencia que se ajuste a tus necesidades y haz clic en "Siguiente".

6. Establece la hora y la fecha en la que deseas que se ejecute la tarea diariamente. Haz clic en "Siguiente".

7. En la siguiente pantalla, selecciona "Iniciar un programa" y haz clic en "Siguiente".

8. En el campo "Programa o script", proporciona la ruta completa al ejecutable de Python del entorno virtual. Ruta relativa desde el repositorio: 
    codeChallenge\venv\Scripts\python.exe

9. En el campo "Agregar argumentos (opcional)", debes proporcionar la ruta del script. Ruta relativa desde el repositorio:
    codeChallenge\src\etl_script.py

10. Haz clic en "Finalizar" para crear la tarea.

11. Ver谩s la tarea en la lista de tareas programadas. Puedes hacer clic derecho en ella y seleccionar "Ejecutar" para probarla de inmediato.

12. La tarea se ejecutar谩 autom谩ticamente seg煤n la programaci贸n que hayas establecido.


## Informaci贸n Adicional

*Notas sobre la Carga de Datos en BigQuery*

Durante el proceso, me encontr茅 con un desaf铆o inesperado al cargar el archivo completo de datos en BigQuery. Aunque BigQuery es completamente capaz de manejar conjuntos de datos mucho m谩s grandes de lo que estaba intentando cargar, experiment茅 problemas con el archivo espec铆fico.

El archivo original es muy grande y, despu茅s de varias pruebas y diagn贸sticos, determin茅 que el problema no era el tama帽o del archivo en s铆, sino posiblemente la calidad, estructura o alg煤n registro espec铆fico dentro del archivo que estaba causando problemas.

La soluci贸n que implement茅 fue reducir el tama帽o del archivo para aislar y excluir registros problem谩ticos, lo que me permiti贸 cargar una porci贸n m谩s manejable y limpia del conjunto de datos en BigQuery sin problemas. Esta estrategia es 煤til en escenarios donde el diagn贸stico detallado de cada registro en un conjunto de datos muy grande es impr谩ctico, y donde un subconjunto de datos sigue siendo representativo para el an谩lisis y en caso de necesitar todos los datos se fragmentariamos el archivo en partes relativamente iguales y subiriamos por partes en el proceso.

*Sobre Ramificaci贸n y Fusi贸n en Git*

Durante el desarrollo del proyecto, tom茅 la decisi贸n consciente de no utilizar la funcionalidad de ramificaci贸n (branching) y fusi贸n (merging) de Git. La raz贸n principal detr谩s de esta elecci贸n es la naturaleza relativamente peque帽a y directa del proyecto.

Al enfrentar este desaf铆o t茅cnico, consider茅 que el proyecto no requer铆a ramificaciones adicionales debido a su escala. Adem谩s, gracias al manejo eficaz de errores, pude identificar y corregir r谩pidamente cualquier problema que surgiera, lo que me permiti贸 mantener un flujo de trabajo eficiente sin la necesidad de ramificar.

Reconozco que la ramificaci贸n y la fusi贸n son pr谩cticas valiosas en el control de versiones, especialmente en proyectos m谩s grandes o colaborativos. Sin embargo, para este proyecto en particular, sent铆 que pod铆a ofrecer una soluci贸n de calidad sin recurrir a ellas.

Estoy consciente de que el desaf铆o solicitaba el uso de estas t茅cnicas, y agradezco la comprensi贸n en esta decisi贸n. Siempre estoy abierta a recibir retroalimentaci贸n y aprender de las experiencias para mejorar en futuros proyectos.


## Contribuciones

Este proyecto fue desarrollado como parte de un desaf铆o t茅cnico. Cualquier feedback es bienvenido.

## Contacto

Stivaly Gomez - stivaly.g@hotmail.com

